# ðŸ§­ Ã‰volution dâ€™Apache Spark â€” de 1.x Ã  4.x (FR)

Ce document rÃ©capitule **les grandes Ã©volutions** dâ€™Apache Spark, avec **compatibilitÃ©s (Java/Scala/Hadoop)**, **features clÃ©s**, **changements dâ€™API**, et **impacts architecturaux**. Il inclut une **section dÃ©taillÃ©e sur lâ€™unification Spark 2** (*SparkSession = SparkContext + SQLContext/HiveContext + Streaming*) et un **chapitre â€œNouveautÃ©s Spark 4.0.0â€**.

---

## ðŸ—ºï¸ Vue dâ€™ensemble (tableau synthÃ¨se)

| Version Spark | PÃ©riode | Java | Scala | Hadoop/YARN | Points clÃ©s | Impact architectural |
|---|---:|---:|---:|---:|---|---|
| **1.0â€“1.6** | 2014â€“2016 | 7/8 | 2.10/2.11 | 2.2â€“2.7 | RDD, DStream, SQL (naissant), MLlib, GraphX | 1Ê³áµ‰ gen. : batch inâ€‘memory, alternative Ã  MapReduce |
| **2.0â€“2.4** | 2016â€“2019 | 8 | 2.11/2.12 | 2.7+ | **DataFrame/Dataset**, **SparkSession**, **Structured Streaming**, Tungsten 1.0, Catalyst | Unification SQL/Streaming, moteur vectorisÃ© |
| **3.0â€“3.2** | 2020â€“2022 | 11 | 2.12/2.13 | 3.2+ | **AQE**, Dynamic Partition Pruning, K8s stable (3.1), ANSI | Cloudâ€‘native, exÃ©cution adaptative |
| **3.3â€“3.5** | 2023â€“2025 | 17/21 | 3.3/3.4 | 3.3.6 | Shuffle Merge, Broadcast amÃ©liorÃ©, **Pandas API on Spark**, Iceberg/Delta/Hudi | Industrialisation & connecteurs modernes |
| **4.0.x** | 2025+ | 17/21 | 3.4+ | 3.3+ | **Spark Connect**, **VARIANT**, Tungsten 2.0, Catalyst v2, **OpenTelemetry**, ANSI par dÃ©faut | Plateâ€‘forme analytique unifiÃ©e, observabilitÃ© native |

> NB : Les valeurs â€œJava/Scala/Hadoopâ€ indiquent les versions **minimales/mises en avant** par la communautÃ©/Ã©diteurs au moment de sortie.

---

## ðŸ”µ Spark 1.x (2014â€“2016) â€” RDD & DStream

### CompatibilitÃ©
- **Java** : 7 â†’ 8 â€¢ **Scala** : 2.10 â†’ 2.11 â€¢ **Hadoop** : 2.2 â†’ 2.7 â€¢ Managers : Standalone, **YARN**, Mesos

### Features majeures
- **RDD** immuables (transformations `map`, `flatMap`, `reduceByKey`â€¦) â€¢ **Cache/persist()**
- **Spark SQL** initial (SchemaRDD/DataFrame via HiveContext)
- **Spark Streaming (DStream)** microâ€‘batch
- **MLlib** (pipelines de ML) â€¢ **GraphX** (graphes)

### Architecture interne
- **DAG Scheduler** + Task Scheduler â€¢ Shuffle par fichiers temporaires
- SÃ©rialisation Java/Kryo â€¢ Pas dâ€™optimisation dynamique

### Impact
- Remplacement de MapReduce pour lâ€™analytique batch en mÃ©moire (Ã—10â€“100 plus rapide).

---

## ðŸŸ£ Spark 2.x (2016â€“2019) â€” SQL unifiÃ© & gestion mÃ©moire

### CompatibilitÃ©
- **Java** : 8 â€¢ **Scala** : 2.11/2.12 â€¢ **Hadoop** : 2.7+ â€¢ Managers : YARN, Mesos, Standalone

### Features majeures
- **API DataFrame/Dataset unifiÃ©e** (typage + optimisations)
- **SparkSession** (remplace `SQLContext`/`HiveContext`, coordonne tout)
- **Structured Streaming** (2.3+) avec exactlyâ€‘once et intÃ©gration Kafka
- **Catalyst** (plan logique â†’ physique) + **Tungsten 1.0** (mÃ©moire offâ€‘heap, vectorisation)
- Lecteurs **Parquet/ORC** vectorisÃ©s, **Wholeâ€‘Stage CodeGen**

### ðŸ§© **Unification des contextes (trÃ¨s important)**
**Avant Spark 2** :  
- `SparkContext` pour RDD, `SQLContext/HiveContext` pour SQL/Hive, `StreamingContext` pour DStreams â†’ **3 contextes distincts**.

**Avec Spark 2** : **`SparkSession` regroupe tout** :

```scala
val spark = SparkSession.builder()
  .appName("UnifiedContext")
  .master("yarn")
  .getOrCreate()

// AccÃ¨s aux anciens contextes via la mÃªme session
spark.sparkContext      // Ã©quivalent ancien SparkContext
spark.sql("SELECT 1")   // SQL direct
// Structured Streaming sur la mÃªme session
val streamDf = spark.readStream.format("kafka").option("subscribe","rides").load()
```

**ConsÃ©quences architecturales :**
- Un seul point dâ€™entrÃ©e/configuration (`spark.conf`)  
- Caches & catalogues partagÃ©s â€¢ UDFs centralisÃ©es  
- Coexistence naturelle **batch + SQL + streaming** dans **une mÃªme session**  
- Migration facilitÃ©e des apps 1.x â†’ 2.x (via `SparkSession`)

### Impact
- Spark devient **SQLâ€‘first** et **pipelineâ€‘ready** ; 3â€“5Ã— plus rapide sur workloads anal. courants.

---

## ðŸŸ¢ Spark 3.x (2020â€“2025) â€” Cloudâ€‘native & adaptatif

### CompatibilitÃ©
- **Java** : 11 / 17 / 21 â€¢ **Scala** : 2.12 / 2.13 / 3.x â€¢ **Hadoop** : 3.2+ â€¢ **K8s** : stable (3.1+)

### Features majeures
- **AQE (Adaptive Query Execution)** : fusion partitions, gestion **skew join**, plan de join modifiÃ© **Ã  lâ€™exÃ©cution**
- **Dynamic Partition Pruning** â€¢ **ANSI** mode â€¢ **UI SQL** amÃ©liorÃ©e
- **Support Kubernetes** firstâ€‘class (Spark Operator) â€¢ **Pandas API on Spark** (Koalas)
- **Shuffle merge**, broadcast amÃ©liorÃ© â€¢ Connecteurs **Iceberg/Hudi/Delta**

### Architecture interne
- Catalyst enrichi de statistiques runtime â€¢ Tungsten â€œ1.5â€ (gestion mÃ©moire & vectorisation stabilisÃ©es)
- Cloud storage natif (S3A/GCS/ADLS), history server amÃ©liorÃ©

### Impact
- Spark devient **cloudâ€‘ready** et **autoâ€‘adaptatif**, idÃ©al pour ETL/BI/ML unifiÃ©s.

---

## ðŸŸ  Spark 4.0.0 (2025+) â€” Connect & ObservabilitÃ©

### CompatibilitÃ©
- **Java** : 17/21 â€¢ **Scala** : 3.4+ â€¢ **Hadoop** : 3.3+ â€¢ **K8s** : 1.25+ â€¢ **Python** : 3.9+

### NouveautÃ©s clÃ©s
1) **Spark Connect** (gRPC) â€” client/serveur distant (Python/Scala/Java/Go/Rust/Swift) :
```python
from pyspark.sql import SparkSession
spark = SparkSession.builder.remote("sc://cluster:15002").getOrCreate()
df = spark.read.csv("s3a://data/rides.csv", header=True)
```
2) **Type `VARIANT`** â€” stockage JSON semiâ€‘structurÃ© natif :
```sql
CREATE TABLE t(id BIGINT, meta VARIANT);
INSERT INTO t VALUES (1, '{"price":12,"city":"Paris"}');
SELECT meta.price FROM t;
```
3) **Tungsten 2.0** & **Catalyst v2** â€” exÃ©cution vectorielle et planification coÃ»t revues  
4) **OpenTelemetry & Audit events JSON** â€” observabilitÃ© standardisÃ©e  
5) **ANSI SQL par dÃ©faut** â€” erreurs strictes si conversions risquÃ©es

### Impact
- Plateâ€‘forme analytique **unifiÃ©e et observable** â€¢ **Multiâ€‘langage** complet â€¢ Meilleur support des **lakehouses** (Delta/Iceberg/Hudi).

---

## ðŸ§ª Matrice de compatibilitÃ© (rÃ©fÃ©rence rapide)

| Spark | Java | Scala | Hadoop | Managers |
|---:|---:|---:|---:|---|
| 1.6 | 7/8 | 2.10/2.11 | 2.2â€“2.7 | YARN, Mesos, Standalone |
| 2.4 | 8 | 2.11/2.12 | 2.7+ | YARN, Mesos, Standalone |
| 3.2 | 11 | 2.12/2.13 | 3.2+ | **YARN, K8s**, Standalone |
| 3.5 | 17/21 | **3.3/3.4** | 3.3.6 | YARN, **K8s** |
| 4.0 | 17/21 | **3.4+** | 3.3+ | YARN, **K8s** |

> Pour Python : PySpark 4 requiert Python **3.9+**.

---

## ðŸ“Œ Implications de design par version (guidelines)

- **1.x** : Ã‰viter les nouveaux projets en RDD/DStream pur. Migrer vers DataFrame/Structured Streaming.  
- **2.x** : Standardiser `SparkSession`, DataFrames/Datasets. Centraliser config & UDFs.  
- **3.x** : Activer **AQE**, utiliser **K8s** ou EMR 6/7, prÃ©fÃ©rer **Iceberg/Delta**.  
- **4.x** : Envisager **Spark Connect**, adopter `VARIANT` pour semiâ€‘structurÃ©, activer **OpenTelemetry**.

---

## ðŸ“š RÃ©fÃ©rences de migration
- 1.x â†’ 2.x : remplacer `SQLContext/HiveContext/StreamingContext` par **`SparkSession`** + **Structured Streaming**.  
- 2.x â†’ 3.x : activer **AQE**, corriger comportements **ANSI** et revoir les UDFs.  
- 3.x â†’ 4.x : tester **Spark Connect**, valider compat matrices (Java/Scala/Hadoop), migrer monitorings vers **OpenTelemetry**.

---

**Fin.** Ce document est prÃªt Ã  Ãªtre versionnÃ© aux cÃ´tÃ©s de tes parties 5A/5B/6A/6B pour donner la **vision dâ€™ensemble** Ã  lâ€™Ã©quipe (ops, data eng, architectes).

