# üß± Scala Expert ‚Äî Partie 5B : Mise en production Spark (FR)

**Objectif** : D√©ployer, surveiller et tuner des jobs **Apache Spark** en production, avec exemples `spark-submit`, zoom **shuffle/AQE**, templates **YAML/JSON**, et **check‚Äëlist** finale. (Inclut une section **troubleshooting**).

---

## 1) Architecture & d√©ploiement (rappel express)

- **Driver** : planifie, envoie les t√¢ches, collecte les r√©sultats.  
- **Executors** : ex√©cutent les tasks; m√©moire + CPU.  
- **Cluster manager** : **YARN**, **Kubernetes**, **Standalone**, **EMR/Dataproc**.  
- **Packaging** : `sbt assembly` ‚Üí JAR **fat/uber** (avec d√©pendances n√©cessaires).

```bash
# Assembly typique
sbt clean test assembly
# Jar en target/scala-3.x/mon-app-assembly-<version>.jar
```

> En prod, le `--master` est fourni par le cluster; en local, utilisez `local[*]` pour les tests.

---

## 2) `spark-submit` ‚Äî recettes pr√™tes √† l‚Äôemploi

### 2.1 AWS EMR (YARN)
```bash
spark-submit \
  --deploy-mode cluster \
  --class com.miaradia.spark.MiaradiaSparkApp \
  --conf spark.executor.cores=5 \
  --conf spark.executor.memory=24g \
  --conf spark.executor.memoryOverhead=3g \
  --conf spark.sql.shuffle.partitions=600 \
  --conf spark.sql.adaptive.enabled=true \
  --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \
  s3://miaradia-artifacts/jars/miaradia-etl-assembly.jar \
  s3://miaradia-data/rides.csv \
  s3://miaradia-data/cities.csv \
  s3://miaradia-out
```
**Notes** :  
- Sur EMR, les r√¥les IAM g√®rent l‚Äôacc√®s S3; v√©rifiez les **bucket policies**.  
- Ajoutez `--jars` pour libs externes (connecteurs JDBC, etc.).

### 2.2 Kubernetes (Spark-on-K8s)
```bash
spark-submit \
  --master k8s://https://<API_SERVER> \
  --deploy-mode cluster \
  --name miaradia-spark-job \
  --class com.miaradia.spark.MiaradiaSparkApp \
  --conf spark.kubernetes.container.image=ghcr.io/miaradia/spark:3.5.1 \
  --conf spark.executor.instances=40 \
  --conf spark.executor.cores=5 \
  --conf spark.executor.memory=24g \
  --conf spark.executor.memoryOverhead=3g \
  --conf spark.sql.adaptive.enabled=true \
  --conf spark.sql.shuffle.partitions=600 \
  --conf spark.kubernetes.namespace=data \
  --conf spark.kubernetes.executor.request.cores=5 \
  --conf spark.kubernetes.driverEnv.LOG_LEVEL=INFO \
  local:///opt/spark/jars/miaradia-etl-assembly.jar \
  s3a://miaradia-data/rides.csv s3a://miaradia-data/cities.csv s3a://miaradia-out
```
**Notes** :  
- Image Docker doit inclure le JAR; sinon utilisez `--jars` + `spark.kubernetes.file.upload.path`.  
- Pour S3 : configurez `fs.s3a.*` via `core-site.xml` ou `--conf` (cl√©/secret ou IAM r√¥le via IRSA).

---

## 3) Zoom technique : Shuffle & AQE (approfondi)

### 3.1 Quand le shuffle appara√Æt ?
- `groupBy`, `join`, `distinct`, `orderBy`, `repartition`, certaines `window`.  
- **Effet** : r√©partition des lignes par cl√© ‚Üí √©critures **shuffle write** (disque) puis **shuffle read**.

### 3.2 O√π sont les fichiers ?
- Sur disque local des executors (`spark.local.dir`) + tampons m√©moire (off-heap / overhead).

### 3.3 Comment *limiter/contourner* un shuffle ?
- **R√©duire t√¥t** : `select` minimal + `filter` en amont.  
- **Broadcast** des petites dimensions : `join(broadcast(dim), ...)`.  
- **Bucketing** + **sorted** par cl√© sur tables r√©currentes.  
- **Map-side combine** / pr√©‚Äëagr√©gations locales.  
- **AQE** : active `spark.sql.adaptive.enabled=true` pour fusion partitions, `skewJoin`.

### 3.4 Lire un plan d‚Äôex√©cution
```scala
df.explain("extended") // Exchange = shuffle, BroadcastHashJoin = pas de shuffle c√¥t√© petite table
```

### 3.5 AQE ‚Äî r√©glages utiles
```bash
--conf spark.sql.adaptive.enabled=true
--conf spark.sql.adaptive.coalescePartitions.enabled=true
--conf spark.sql.adaptive.skewJoin.enabled=true
```

---

## 4) Templates prod ‚Äî YAML / JSON / spark-defaults

### 4.1 Spark-on-K8s (YAML minimal)
```yaml
apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: miaradia-spark-job
  namespace: data
spec:
  type: Scala
  mode: cluster
  image: ghcr.io/miaradia/spark:3.5.1
  mainClass: com.miaradia.spark.MiaradiaSparkApp
  mainApplicationFile: local:///opt/spark/jars/miaradia-etl-assembly.jar
  sparkVersion: "3.5.1"
  driver:
    cores: 2
    memory: 4g
    serviceAccount: spark-sa
  executor:
    instances: 40
    cores: 5
    memory: 24g
  deps:
    jars: []
  sparkConf:
    "spark.sql.adaptive.enabled": "true"
    "spark.sql.shuffle.partitions": "600"
    "spark.serializer": "org.apache.spark.serializer.KryoSerializer"
```

### 4.2 EMR ‚Äî configuration JSON (extrait)
```json
{
  "Classification": "spark-defaults",
  "Properties": {
    "spark.sql.adaptive.enabled": "true",
    "spark.sql.shuffle.partitions": "600",
    "spark.serializer": "org.apache.spark.serializer.KryoSerializer"
  }
}
```

### 4.3 `spark-defaults.conf` (comment√©)
```properties
spark.sql.adaptive.enabled=true
spark.sql.shuffle.partitions=600
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.executor.cores=5
spark.executor.memory=24g
spark.executor.memoryOverhead=3g
```

---

## 5) Monitoring & observabilit√©

### 5.1 Spark UI
- **Stages** (temps, tasks, skew), **Storage** (cache), **SQL** (plans).  
- Rep√©rer `Exchange`, `SortMergeJoin`, `BroadcastHashJoin`.

### 5.2 Prometheus + Grafana
- Activer m√©triques :  
  ```bash
  --conf spark.metrics.conf=metrics.properties
  ```
- Suivre : CPU par task, **GC time**, **shuffle spill**, m√©moire, StateStore (streaming).

### 5.3 Logs structur√©s (ELK)
- Logback JSON ‚Üí ingestion ELK/Opensearch; corr√©lation par `appId`, `stageId`, `jobId`.

---

## 6) Tuning en production (r√©cap)

- **M√©moire** : 16‚Äì32 Go heap/executor + overhead 7‚Äì10 %.  
- **C≈ìurs** : 4‚Äì6 / executor (√©viter ‚Äúfat executors‚Äù).  
- **Partitions** : 2‚Äì3√ó c≈ìurs totaux; Parquet 128‚Äì256 Mo.  
- **Serializer** : **Kryo** recommand√©.  
- **Cache** cibl√© (r√©utilisation multiple).  
- **Shuffle** : AQE on, broadcast si petite dimension, bucketing si r√©utilis√©.  
- **I/O** : limiter petits fichiers (coalesce); pr√©f√©rer Parquet.

---

## 7) Check‚Äëlist pr√©‚Äëproduction (go‚Äëlive)

- [ ] **Dimensionnement** valid√© (cf. Partie 5A)  
- [ ] **Plan sans shuffles inutiles** (`explain`)  
- [ ] **AQE activ√©e** + skew join si besoin  
- [ ] **Logs** (niveau, format JSON si ELK)  
- [ ] **Metrics** (Prometheus/Grafana)  
- [ ] **S√©curit√©** (IAM/Kerberos/SA), acc√®s S3/HDFS OK  
- [ ] **Data Quality** (√©chantillons, r√®gles)  
- [ ] **CI/CD** basique (build + tests + d√©ploiement)  
- [ ] **Rollback** pr√©vu (version jar pr√©c√©dente)  
- [ ] **Alerte SLA** (latence, throughput, √©checs)  

---

## 8) Troubleshooting (pannes courantes & correctifs)

### 8.1 `ExecutorLostFailure` / executors qui disparaissent
- **Causes** : OOM, node preempted (K8s), r√©seau.  
- **Fix** : r√©duire heap par JVM mais augmenter le **nombre** d‚Äôexecutors; v√©rifier GC; surveiller noeuds K8s.

### 8.2 `OutOfMemoryError: GC overhead limit exceeded`
- **Causes** : heap trop pleine, gros shuffles.  
- **Fix** : r√©duire taille partitions, **augmenter parallelisme**, `persist(MEMORY_AND_DISK)`, v√©rifier objets volumineux/UDF.

### 8.3 `Shuffle fetch failed`
- **Causes** : fichiers shuffle perdus/corrup, executors morts.  
- **Fix** : augmenter **retries**, stabiliser cluster, v√©rifier disque local, activer **AQE**.

### 8.4 `java.io.FileNotFoundException` (S3)
- **Causes** : permissions, chemins, √©ventuelle latence S3.  
- **Fix** : r√¥les IAM, chemins `s3a://`, r√©essais, consistency EMRFS si besoin.

### 8.5 Skew extr√™me (cl√© chaude)
- **Sympt√¥me** : t√¢ches tr√®s longues sur quelques partitions.  
- **Fix** : **salting**, **broadcast** petite table, **AQE skew** on, **bucketing** par cl√©.

---

## 9) Annexes ‚Äî commandes utiles

```bash
# Voir config effective
spark-submit --version

# Debug niveau SQL plan
spark.sql.debug.maxToStringFields=200

# Exemple d‚Äôexplain complet depuis spark-shell
spark.read.parquet("/path").where("price > 0").explain(true)
```

---

**Fin ‚Äî Partie 5B.**  
Prochaine partie (6) : **Industrialisation & Architecture Spark** (Airflow, Deequ, Terraform, CI/CD, s√©curit√©, lineage, comparatifs).
